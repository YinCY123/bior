---
title: "scran"
author: "YinCY"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
Single-cell RNA sequencing (scRNA-seq) is a widely used technique for profiling gene expression in individual cells. This allows molecular biology to be studied at a resolution that cannot be matched by bulk sequencing of cell populations. The scran package implements methods to perform low-level processing of scRNA-seq data, including cell cycle phase assignment, variance modelling and testing for marker genes and gene-gene correlations. This vignette provides brief descriptions of these methods and some toy examples to demonstrate their use.

# Setting up the data
We start off with a count matrix where each row is a gene and each column is a cell. These can be obtained by mapping read sequences to a reference genome, and then counting the number of reads mapped to the exons of each gene. (See, for example, the `Rsubread` package to do both of these tasks.) Alternatively, pseudo-alignment methods can be used to quantify the abundance of each transcript in each cell. For simplicity, we will pull out an existing dataset from the `scRNAseq` package.

```{r}
library(scRNAseq)
sce <- GrunPancreasData()
sce
```

This particular dataset is taken from a study of the human pancreas with the CEL-seq protocol (Grun et al. 2016). It is provided as a `SingleCellExperiment` object (from the `SingleCellExperiment` package), which contains the raw data and various annotations. We perform some cursory quality control to remove cells with low total counts or high spike-in percentages:

```{r}
library(scuttle)
library(magrittr)
qcstats <- perCellQCMetrics(sce)
qcfilter <- quickPerCellQC(qcstats, percent_subsets = "altexps_ERCC_percent")
sce <- sce[, !qcfilter$discard]
qcfilter$discard %>% summary
```

Cell-specific biases are normalized using the `computeSumFactors()` method, which implements the deconvolution strategy for scaling normalization (Lun, Bach, and Marioni 2016).

```{r}
library(scran)
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, clusters = clusters)
sizeFactors(sce) %>% summary
sce <- logNormCounts(sce)
```

# Variance modeling
We identify genes that drive biological heterogeneity in the data set by modelling the per-gene variance. By only using a subset of highly variable genes in downstream analyses like clustering, we improve resolution of biological structure by removing uninteresting genes driven by technical noise. We decompose the total variance of each gene into its biological and technical components by fitting a trend to the endogenous variances (Lun, McCarthy, and Marioni 2016). The fitted value of the trend is used as an estimate of the technical component, and we subtract the fitted value from the total variance to obtain the biological component for each gene.

```{r}
dec <- modelGeneVar(sce)
plot(dec$mean, dec$total)
curve(metadata(dec)$trend(x), col = "blue", add = T)
```

If we have spike-ins, we can use them to fit the trend instead. This provides a more direct estimate of the technical variance and avoids assuming that most genes do not exhibit biological variaility.

```{r}
dec2 <- modelGeneVarWithSpikes(sce, spikes = "ERCC")

metadata(dec2)
plot(dec2$mean, dec2$total)
points(metadata(dec2)$mean, metadata(dec2)$var, col = "red")
curve(metadata(dec2)$trend(x), col = "blue", add = T)
```

If we have some uninteresting factors of variation, we can block on these using `block=`. This will perform the trend fitting and decomposition within each block before combining the statistics across blocks for output. Statistics for each individual block can also be extracted for further inspection.

```{r}
dec3 <- modelGeneVar(sce, block = sce$donor, density.weight = F)
per.block <- dec3$per.block

par(mfrow = c(3, 2))
for(i in seq_along(per.block)){
  decx <- per.block[[i]]
  plot(decx$mean, decx$total, 
       xlab = "Mean log-expression", 
       ylab = "Variance", 
       main = names(per.block)[i])
  curve(metadata(decx)$trend(x), col = "blue", add = T)
}
```

We can then extract some top genes for use in downstream procedures using the  `getTopHVGs()` function. A variety of different strategies can be used to define a subset of interesting genes:

```{r}
# get the top 10% of genes
top.hvgs <- getTopHVGs(dec, prop = 0.1)

# get the top 2000 genes
top.hvgs2 <- getTopHVGs(dec, n = 2000)

# get all genes with positive biological components
top.hvgs3 <- getTopHVGs(dec, var.threshold = 0)

# get all genes with FDR below 5%
top.hvgs4 <- getTopHVGs(dec, fdr.threshold = 0.05)
```

The selected subset of genes can then be passed to the subset.row argument (or equivalent) in downstream steps. This process is demonstrated below for the PCA step:

```{r}
sce <- fixedPCA(sce, subset.row = top.hvgs)
reducedDimNames(sce)
```

# Automated PC choice
Principal components analysis is commonly performed to denoise and compact the data prior to downstream analysis. A common question is how many PCs to retain; more PCs will capture more biological signal at the cost of retaining more noise and requiring more computational work. One approach to choosing the number of PCs is to use the technical component estimates to determine the proportion of variance that should be retained. This is implemented in  `denoisePCA()`, which takes the estimates returned by `modelGeneVar()` or friends. (For greater accuracy, we use the fit with the spikes; we also subset to only the top HVGs to remove noise.)

```{r}
sced <- denoisePCA(sce, dec2, subset.row = getTopHVGs(dec2, prop = 0.1))
reducedDim(sced, "PCA") %>% dim
```

Another approach is based on the assumption that each subpopulation should be separated from each other on a different axis of variation. Thus, we choose the number of PCs that is not less than the number of subpopulations (which are unknown, of course, so we use the number of clusters as a proxy). It is then a simple matter to subset the dimensionality reduction result to the desired number of PCs.

```{r}
output <- getClusteredPCs(reducedDim(sce))
npcs <- metadata(output)$chosen
reducedDim(sce, "PCAsub") <- reducedDim(sce, "PCA")[, 1:npcs, drop = F]
sce
```

# Graph-based clustering
























